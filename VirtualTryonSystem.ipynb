{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "VirtualTryonSystem.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "UyrSIdKfbn6V",
        "FXhRBpIHlTAW",
        "C4Dpy1nkdKm5",
        "V5aUNr8_KEJE",
        "jg5mpVkmAnpS",
        "QPblQfVyHaLf",
        "uKd7NWztUINU",
        "Vjfpc9NNUMdR",
        "4uqbqrl-USsq",
        "Bl7Qbmsri0Gm",
        "fencgo_Mi3f8",
        "TgZcZhu5GHxd",
        "DhJAgd0FTr2d",
        "7Cjwy21ZT3ZV",
        "cyD0Ml9AT7ut",
        "Fhza6dAxPaOZ",
        "SeKdlNQcKLFb",
        "teIykXZQoV_x",
        "GlCm6S-H58Yw"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b28b8e8919fb433a930227ac68fab635": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_03c199916cdb41f0a5d0afee08cd6bbe",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2e5e286d2d544133af09caf5b4e57086",
              "IPY_MODEL_94849ba8d37849cd8d972001a844d4e3"
            ]
          }
        },
        "03c199916cdb41f0a5d0afee08cd6bbe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2e5e286d2d544133af09caf5b4e57086": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_72242ea126ad41a2b222daa391d7622f",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 574673361,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 574673361,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_004d871d5b1945d69ac75da2e0e1206e"
          }
        },
        "94849ba8d37849cd8d972001a844d4e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4acdf7a0dc8043719483d34f7934a0b3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 548M/548M [00:14&lt;00:00, 39.4MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_42418d32cbf9423d9701c812002220fb"
          }
        },
        "72242ea126ad41a2b222daa391d7622f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "004d871d5b1945d69ac75da2e0e1206e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4acdf7a0dc8043719483d34f7934a0b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "42418d32cbf9423d9701c812002220fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UyrSIdKfbn6V"
      },
      "source": [
        "#ライブラリインポート\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJPhvzT0-Btt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "b28b8e8919fb433a930227ac68fab635",
            "03c199916cdb41f0a5d0afee08cd6bbe",
            "2e5e286d2d544133af09caf5b4e57086",
            "94849ba8d37849cd8d972001a844d4e3",
            "72242ea126ad41a2b222daa391d7622f",
            "004d871d5b1945d69ac75da2e0e1206e",
            "4acdf7a0dc8043719483d34f7934a0b3",
            "42418d32cbf9423d9701c812002220fb"
          ]
        },
        "outputId": "630cfc07-16ab-4ff9-b3b5-687b5ebfba2a"
      },
      "source": [
        "from __future__ import print_function\n",
        "#%matplotlib inline\n",
        "import argparse\n",
        "import os\n",
        "import cv2\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.utils as vutils\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "from IPython.display import HTML\n",
        "import time\n",
        "import subprocess as sp\n",
        "from datetime import datetime, timedelta, timezone\n",
        "import math\n",
        "from torchvision import datasets, models, transforms\n",
        "import torch.nn.functional as F\n",
        "import imageio\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import numpy as np\n",
        "vgg19 = models.vgg19(pretrained=True)\n",
        "!pip install ninja\n",
        "device=torch.device(\"cuda:0\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg19-dcbb9e9d.pth\" to /root/.cache/torch/hub/checkpoints/vgg19-dcbb9e9d.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b28b8e8919fb433a930227ac68fab635",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=574673361.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Collecting ninja\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1d/de/393468f2a37fc2c1dc3a06afc37775e27fde2d16845424141d4da62c686d/ninja-1.10.0.post2-py3-none-manylinux1_x86_64.whl (107kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 6.8MB/s \n",
            "\u001b[?25hInstalling collected packages: ninja\n",
            "Successfully installed ninja-1.10.0.post2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FXhRBpIHlTAW"
      },
      "source": [
        "#GPU使用時間と種類を表示"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8BydTpdanEi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01122b87-5496-44d0-e160-0bdc4def56e5"
      },
      "source": [
        "res = sp.Popen([\"cat\", \"/proc/uptime\"], stdout=sp.PIPE)\n",
        "    # 単位はHour\n",
        "use_time = float(sp.check_output([\"awk\", \"{print $1 /60 /60 }\"], stdin=res.stdout).decode().replace(\"\\n\",\"\"))\n",
        "print(use_time)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0666833\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FISVOABV_HpC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d0a457f-1655-4da4-8ca4-87efdd926be3"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu Feb 11 11:04:56 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.39       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   33C    P0    25W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C4Dpy1nkdKm5"
      },
      "source": [
        "#マウント"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYmiIYO883bl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99edb6f5-c99e-432b-a1df-9b16a260e5f1"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5aUNr8_KEJE"
      },
      "source": [
        "#準備"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jg5mpVkmAnpS"
      },
      "source": [
        "##パラメータ定義"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-e8Gtv_nvz_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6c81be3-6081-4a2e-e4ad-a0c0a8411793"
      },
      "source": [
        "%cd drive/MyDrive/\r\n",
        "num_thread=0\r\n",
        "img_size=(128,96)\r\n",
        "lr=0.0002\r\n",
        "b1=0.5\r\n",
        "b2=0.999\r\n",
        "ngpu=1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QPblQfVyHaLf"
      },
      "source": [
        "##関数定義"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uKd7NWztUINU"
      },
      "source": [
        "###切り抜き"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_fX6wAW0HYZW"
      },
      "source": [
        "def overlay(p,f,tops,pants,skirt):\n",
        "  Mask=(tops+pants+skirt)\n",
        "  Mask=MaskTrans(Mask)\n",
        "  #print(Mask.size())\n",
        "  #print(p.size())\n",
        "  reverse=1-Mask\n",
        "  cutout1=p*reverse\n",
        "  #print(f[0][0][113][50],Mask[0][0][113][50])\n",
        "  #print(Mask.size(),f[0].size())\n",
        "  cutout2=Mask*f\n",
        "  #print(cutout2[0][0][113][50])\n",
        "  out=cutout1+cutout2\n",
        "  return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vjfpc9NNUMdR"
      },
      "source": [
        "###mask閾値"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fosipO__eToJ"
      },
      "source": [
        "def  MaskTrans(mask):\n",
        "  for i in range(mask.size(0)):\n",
        "    for j in range(mask.size(1)):\n",
        "      for k in range(mask.size(2)):\n",
        "        for l in range(mask.size(3)):\n",
        "          if mask[i][j][k][l]>0.6:\n",
        "            mask[i][j][k][l]=1\n",
        "          else:\n",
        "            mask[i][j][k][l]=0\n",
        "  \n",
        "  return mask"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4uqbqrl-USsq"
      },
      "source": [
        "###重みの初期化"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uC9OpGtJOkg7"
      },
      "source": [
        "def init_weights(model):\n",
        "  if isinstance(model.modules,nn.Conv2d):\n",
        "      model.modules().weight.data.nomal_(0,0.002)\n",
        "      model.modules().bias.data.zero_()\n",
        "  if isinstance(model.modules,nn.ConvTranspose2d):\n",
        "      model.modules().weight.data.nomal_(0,0.002)\n",
        "      model.modules().bias.data.zero_()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bl7Qbmsri0Gm"
      },
      "source": [
        "###KLDloss\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29T88BldFUMg"
      },
      "source": [
        "def KLDloss(mu, logvar):\n",
        "  lamda=0.05\n",
        "  return lamda*(-0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fencgo_Mi3f8"
      },
      "source": [
        "###Featloss\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D63SiYoMi6i_"
      },
      "source": [
        "def Featloss(t,f):\n",
        "  L1=nn.L1Loss()\n",
        "  lamda=10\n",
        "  size=len(t)\n",
        "  featloss = torch.full((1,), fill_value=0,dtype=torch.float32,device=device)\n",
        "\n",
        "  for i in range(size):\n",
        "    loss=L1(t[i].detach(),f[i])\n",
        "    featloss+=(lamda*loss)\n",
        "\n",
        "  return featloss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TgZcZhu5GHxd"
      },
      "source": [
        "##クラス定義\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DhJAgd0FTr2d"
      },
      "source": [
        "###Encoder-Decoder\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWqoZBW-GMTS"
      },
      "source": [
        "class EncoderDecoder(nn.Module):\n",
        "  def __init__(self,ngpu):\n",
        "    super(EncoderDecoder,self).__init__()\n",
        "    self.ngpu=ngpu\n",
        "    #Encoder\n",
        "    df=3#class\n",
        "    self.down1_1=nn.Conv2d(3*df,32*df,3,2,1,bias=False,groups=3)\n",
        "    self.innorm1_1=nn.InstanceNorm2d(32*df,eps=1e-5)\n",
        "\n",
        "    self.Leaky=nn.LeakyReLU(0.2,inplace=True)\n",
        "    self.down1_2=nn.Conv2d(32*df,64*df,3,2,1,bias=False,groups=3)\n",
        "    self.innorm1_2=nn.InstanceNorm2d(64*df,eps=1e-5)\n",
        "\n",
        "    self.down1_3=nn.Conv2d(64*df,128*df,3,2,1,bias=False,groups=3)\n",
        "    self.innorm1_3=nn.InstanceNorm2d(128*df,eps=1e-5)\n",
        "\n",
        "    self.down1_4=nn.Conv2d(128*df,256*df,3,2,1,bias=False,groups=3)\n",
        "    self.innorm1_4=nn.InstanceNorm2d(256*df,eps=1e-5)\n",
        "\n",
        "    self.gamma=nn.Conv2d(256*df,2*df,(8,6),1,0,bias=False,groups=3)\n",
        "    self.beta=nn.Conv2d(256*df,2*df,(8,6),1,0,bias=False,groups=3)\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    #Decoder\n",
        "    self.down1_0=nn.Conv2d(2*df,256*df,3,1,1,groups=3)\n",
        "\n",
        "    self.relu=nn.ReLU()\n",
        "    self.leaky=nn.LeakyReLU(0.2,inplace=True)\n",
        "\n",
        "    #2block\n",
        "    self.batch2_1=nn.BatchNorm2d(256*df,eps=1e-5,affine=False)\n",
        "    self.pool2_1=nn.MaxPool2d(16)\n",
        "    self.share2_1=nn.Conv2d(df*1,16*df,3,1,1,groups=3)\n",
        "    self.gamma2_1=nn.Conv2d(16*df,256*df,3,1,1,groups=3)\n",
        "    self.beta2_1=nn.Conv2d(16*df,256*df,3,1,1,groups=3)\n",
        "    self.gconv2_1=nn.Conv2d(256*df,256*df,3,1,1,groups=3)\n",
        "    self.up2_1=nn.Upsample(scale_factor=2,mode=\"nearest\")\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "    #3block\n",
        "    self.batch3_1=nn.BatchNorm2d(256*df,eps=1e-5,affine=False)\n",
        "    self.pool3_1=nn.MaxPool2d(8)\n",
        "    self.share3_1=nn.Conv2d(1*df,16*df,3,1,1,groups=3)\n",
        "    self.gamma3_1=nn.Conv2d(16*df,256*df,3,1,1,groups=3)\n",
        "    self.beta3_1=nn.Conv2d(16*df,256*df,3,1,1,groups=3)\n",
        "    self.gconv3_1=nn.Conv2d(256*df,128*df,3,1,1,groups=3)\n",
        "    self.up3_1=nn.Upsample(scale_factor=2,mode=\"nearest\")\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "    #4block\n",
        "    self.batch4_1=nn.BatchNorm2d(128*df,eps=1e-5,affine=False)\n",
        "    self.pool4_1=nn.MaxPool2d(4)\n",
        "    self.share4_1=nn.Conv2d(1*df,16*df,3,1,1,groups=3)\n",
        "    self.gamma4_1=nn.Conv2d(16*df,128*df,3,1,1,groups=3)\n",
        "    self.beta4_1=nn.Conv2d(16*df,128*df,3,1,1,groups=3)\n",
        "    self.gconv4_1=nn.Conv2d(128*df,64*df,3,1,1,groups=3)\n",
        "    self.up4_1=nn.Upsample(scale_factor=4,mode=\"nearest\")\n",
        "    self.smooth4_1=nn.Conv2d(64*df,64*df,3,1,1,groups=3)\n",
        "\n",
        "    \n",
        "\n",
        "    #5block\n",
        "    self.batch5_1=nn.BatchNorm2d(64*df,eps=1e-5,affine=False)\n",
        "    self.pool5_1=nn.MaxPool2d(1)\n",
        "    self.share5_1=nn.Conv2d(1*df,16*df,3,1,1,groups=3)\n",
        "    self.gamma5_1=nn.Conv2d(16*df,64*df,3,1,1,groups=3)\n",
        "    self.beta5_1=nn.Conv2d(16*df,64*df,3,1,1,groups=3)\n",
        "    self.gconv5_1=nn.Conv2d(64*df,32*df,3,1,1,groups=3)\n",
        "\n",
        "    #+block\n",
        "    self.pbatch=nn.BatchNorm2d(32*df,eps=1e-5,affine=False)\n",
        "    self.ppool=nn.MaxPool2d(1)\n",
        "    self.pshare=nn.Conv2d(1*df,16*df,3,1,1,groups=3)\n",
        "    self.pgamma=nn.Conv2d(16*df,32*df,3,1,1,groups=3)\n",
        "    self.pbeta=nn.Conv2d(16*df,32*df,3,1,1,groups=3)\n",
        "    self.pgconv=nn.Conv2d(32*df,20*df,3,1,1,groups=3)\n",
        "\n",
        "\n",
        "    #lastblock\n",
        "    self.lastconv=nn.Conv2d(20*df,3,1,1,0)\n",
        "    self.sigmoid=nn.Sigmoid()\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "  def Encoder(self,input): \n",
        "    #print(input.size())\n",
        "    down1_1=self.down1_1(input)\n",
        "    innorm1_1=self.innorm1_1(down1_1)\n",
        "    #print(innorm1_1.size())\n",
        "\n",
        "    leaky1_2=self.Leaky(innorm1_1)\n",
        "    down1_2=self.down1_2(leaky1_2)\n",
        "    innorm1_2=self.innorm1_2(down1_2)\n",
        "    #print(innorm1_2.size())\n",
        "\n",
        "    leaky1_3=self.Leaky(innorm1_2)\n",
        "    down1_3=self.down1_3(leaky1_3)\n",
        "    innorm1_3=self.innorm1_3(down1_3)\n",
        "    #print(innorm1_3.size())\n",
        "\n",
        "    leaky1_4=self.Leaky(innorm1_3)\n",
        "    #print(leaky1_4.size())\n",
        "    down1_4=self.down1_4(leaky1_4)\n",
        "    innorm1_4=self.innorm1_4(down1_4)\n",
        "    #print(innorm1_4.size())\n",
        "    \n",
        "    leaky1_5=self.Leaky(innorm1_4)\n",
        "    #print(leaky1_5.size())\n",
        "    gamma=self.gamma(leaky1_5)\n",
        "    beta=self.beta(leaky1_5)\n",
        "    #print(gamma.size(),beta.size())\n",
        "    #print(\"---\"*10)\n",
        "    return gamma,beta\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  def Decoder(self,z,seg,test=False): \n",
        "    \n",
        "    #print(z.size())\n",
        "    down1_0=self.down1_0(z)\n",
        "    #print(down1_0.size())\n",
        "\n",
        "\n",
        "    #2block\n",
        "    batch2_1=self.batch2_1(down1_0)\n",
        "    share2_1=self.relu(self.share2_1(self.pool2_1(seg)))\n",
        "    gamma2_1=self.gamma2_1(share2_1)\n",
        "    beta2_1=self.beta2_1(share2_1)\n",
        "    temp2_1=(batch2_1*gamma2_1)+beta2_1\n",
        "    out2_1=self.up2_1(self.gconv2_1(self.leaky(temp2_1)))\n",
        "    #print(out2_1.size())\n",
        "\n",
        "\n",
        "    #3block\n",
        "    batch3_1=self.batch3_1(out2_1)\n",
        "    share3_1=self.relu(self.share3_1(self.pool3_1(seg)))\n",
        "    gamma3_1=self.gamma3_1(share3_1)\n",
        "    beta3_1=self.beta3_1(share3_1)\n",
        "    #print(batch3_1.size(),gamma3_1.size())\n",
        "    temp3_1=(batch3_1*gamma3_1)+beta3_1\n",
        "    out3_1=self.up3_1(self.gconv3_1(self.leaky(temp3_1)))\n",
        "    #print(out3_1.size())\n",
        "\n",
        "\n",
        "    #4block\n",
        "    batch4_1=self.batch4_1(out3_1)\n",
        "    share4_1=self.relu(self.share4_1(self.pool4_1(seg)))\n",
        "    gamma4_1=self.gamma4_1(share4_1)\n",
        "    beta4_1=self.beta4_1(share4_1)\n",
        "    #print(batch4_1.size(),gamma4_1.size())\n",
        "    temp4_1=(batch4_1*gamma4_1)+beta4_1\n",
        "    out4_1=self.up4_1(self.gconv4_1(self.leaky(temp4_1)))\n",
        "    out4_1=self.smooth4_1(out4_1)\n",
        "    #print(out4_1.size())\n",
        "\n",
        "    \n",
        "    #5block\n",
        "    batch5_1=self.batch5_1(out4_1)\n",
        "    share5_1=self.relu(self.share5_1(self.pool5_1(seg)))\n",
        "    gamma5_1=self.gamma5_1(share5_1)\n",
        "    beta5_1=self.beta5_1(share5_1)\n",
        "    #print(batch5_1.size(),gamma5_1.size())\n",
        "    temp5_1=(batch5_1*gamma5_1)+beta5_1\n",
        "    #for i in range(32):\n",
        "      #vutils.save_image(batch5_1[2,i,:,:],f\"batch5_1_{i}.png\")\n",
        "    #for i in range(32):\n",
        "      #vutils.save_image(gamma5_1[2,i,:,:],f\"gamma5_1_{i}.png\")\n",
        "    #for i in range(32):\n",
        "      #vutils.save_image(beta5_1[2,i,:,:],f\"beta5_1_{i}.png\")\n",
        "    out5_1=self.gconv5_1(self.leaky(temp5_1))\n",
        "    #print(out5_1.size())\n",
        "\n",
        "    #+block\n",
        "    batch=self.pbatch(out5_1)\n",
        "    share=self.relu(self.pshare(self.ppool(seg)))\n",
        "    gamma=self.pgamma(share)\n",
        "    beta=self.pbeta(share)\n",
        "    temp=(batch*gamma)+beta\n",
        "    out=self.pgconv(self.leaky(temp))\n",
        "    #print(out.size())\n",
        "    last=self.leaky(out)   \n",
        "    #for i in range(20):\n",
        "      #vutils.save_image(last[2,i,:,:],f\"last{i}.png\")\n",
        "    out5=self.sigmoid(self.lastconv(last))\n",
        "\n",
        "    return out5,last\n",
        "\n",
        "\n",
        "  def reparameterize(self,mu, logvar):\n",
        "      std = torch.exp(0.5 * logvar) #分散共分散のlogvarを標準偏差stdに変換\n",
        "      #print(std.size())\n",
        "      eps = torch.randn_like(std)/4\n",
        "      #print(mu)\n",
        "      #print(std,eps)\n",
        "      #print(eps.mul(std) + mu)\n",
        "      return eps.mul(std) + mu\n",
        "\n",
        "\n",
        "  def forward(self,input,seg,Z,test=False,pre=False,encodeonly=False):\n",
        "    if not test and not pre and not encodeonly:\n",
        "      mu,logvar=self.Encoder(input)\n",
        "      z=self.reparameterize(mu,logvar)\n",
        "      #print(input.size(),seg.size())\n",
        "      fake,last=self.Decoder(z,seg)\n",
        "      return fake,mu,logvar,z,last\n",
        "    \n",
        "    elif pre==True:\n",
        "      fake,_=self.Decoder(Z,seg,test=True)\n",
        "      return fake\n",
        "\n",
        "    elif encodeonly==True:\n",
        "      mu,logvar=self.Encoder(input)\n",
        "      z=self.reparameterize(mu,logvar)\n",
        "      return z,mu,logvar\n",
        "\n",
        "    else:\n",
        "      z=torch.randn((1,6,1,1)).to(device)\n",
        "      z=z.repeat(seg.size(0),1,1,1)\n",
        "      \n",
        "      fake,_=self.Decoder(z,seg,test=True)\n",
        "      return fake,z"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Cjwy21ZT3ZV"
      },
      "source": [
        "###Discriminator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4EQl2xjyA5A3"
      },
      "source": [
        "class Discriminator(nn.Module):\n",
        "  def __init__(self,ngpu):    \n",
        "    super(Discriminator,self).__init__()\n",
        "    self.ngpu=ngpu\n",
        "    df=3\n",
        "    dc=df+3#class\n",
        "    #1block\n",
        "    self.pool=nn.AvgPool2d(2)\n",
        "    self.down1_1=nn.Conv2d(dc,8*dc,4,2,2)\n",
        "    self.leaky=nn.LeakyReLU(0.2)\n",
        "\n",
        "    #2block\n",
        "    self.down1_2=nn.Conv2d(8*dc,16*dc,4,2,2)\n",
        "    self.innorm1_2=nn.InstanceNorm2d(16*dc)\n",
        "\n",
        "    #3block\n",
        "    self.down1_3=nn.Conv2d(16*dc,32*dc,4,2,2)\n",
        "    self.innorm1_3=nn.InstanceNorm2d(32*dc)\n",
        "\n",
        "    #4block\n",
        "    self.down1_4=nn.Conv2d(32*dc,64*dc,4,1,2)\n",
        "    self.innorm1_4=nn.InstanceNorm2d(64*dc)\n",
        "\n",
        "    #5block\n",
        "    self.down1_5=nn.Conv2d(64*dc,1,4,1,2)\n",
        "    self.sigmoid=nn.Sigmoid()\n",
        "\n",
        "  def Discriminator(self,image,seg): \n",
        "    #print(image.size(),seg.size())\n",
        "    featmap=[]\n",
        "    data=torch.cat([image,seg],dim=1)\n",
        "    \n",
        "    #1block\n",
        "    pool1_1=self.pool(data)\n",
        "    down1_1=self.down1_1(pool1_1)\n",
        "    leaky1_1=self.leaky(down1_1)\n",
        "    featmap.append(leaky1_1)\n",
        "    #print(leaky1_1.size())\n",
        "\n",
        "    #2block\n",
        "    down1_2=self.down1_2(leaky1_1)\n",
        "    innorm1_2=self.innorm1_2(down1_2)\n",
        "    leaky1_2=self.leaky(innorm1_2)\n",
        "    featmap.append(leaky1_2)\n",
        "    #print(leaky1_2.size())\n",
        "\n",
        "    #3block\n",
        "    down1_3=self.down1_3(leaky1_2)\n",
        "    innorm1_3=self.innorm1_3(down1_3)\n",
        "    leaky1_3=self.leaky(innorm1_3)\n",
        "    featmap.append(leaky1_3)\n",
        "    #print(leaky1_3.size())\n",
        "\n",
        "\n",
        "\n",
        "    #4block\n",
        "    down1_4=self.down1_4(leaky1_3)\n",
        "    innorm1_4=self.innorm1_4(down1_4)\n",
        "    leaky1_4=self.leaky(innorm1_4)\n",
        "    featmap.append(leaky1_4)\n",
        "    #print(leaky1_4.size())\n",
        "\n",
        "    down1_5=self.down1_5(leaky1_4)\n",
        "    #print(down1_5.size())\n",
        "    #print(\"---\"*10)\n",
        "\n",
        "    return self.sigmoid(down1_5),featmap"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cyD0Ml9AT7ut"
      },
      "source": [
        "###知覚損失\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXrTi7USTXXN"
      },
      "source": [
        "class Vgg19Loss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Vgg19Loss, self).__init__()\n",
        "        features1=list(vgg19.features)[:3]\n",
        "        features2=list(vgg19.features)[:8]\n",
        "        features3=list(vgg19.features)[:13]\n",
        "        features4=list(vgg19.features)[:22]\n",
        "        features5=list(vgg19.features)[:31]\n",
        "        self.features1=nn.ModuleList(features1).eval()\n",
        "        self.features2=nn.ModuleList(features2).eval()\n",
        "        self.features3=nn.ModuleList(features3).eval()\n",
        "        self.features4=nn.ModuleList(features4).eval()\n",
        "        self.features5=nn.ModuleList(features5).eval()\n",
        "\n",
        "    def forward(self,x,y):\n",
        "        t1=x\n",
        "        t2=y\n",
        "        loss1=nn.MSELoss()\n",
        "        loss2=nn.MSELoss()\n",
        "        loss3=nn.MSELoss()\n",
        "        loss4=nn.MSELoss()\n",
        "        loss5=nn.MSELoss()\n",
        "\n",
        "        for f in self.features1:\n",
        "            x=f(x)\n",
        "            y=f(y)\n",
        "        #print(x,y)\n",
        "        f1loss=torch.sqrt(loss1(x,y)/(64*128*96))\n",
        "    \n",
        "        \n",
        "        x=t1\n",
        "        y=t2\n",
        "        for f in self.features2:\n",
        "            x=f(x)\n",
        "            y=f(y)\n",
        "       # print(x.size(),y.size())\n",
        "        f2loss=torch.sqrt(loss2(x,y)/(128*64*48))\n",
        "\n",
        "        x=t1\n",
        "        y=t2\n",
        "        for f in self.features3:\n",
        "            x=f(x)\n",
        "            y=f(y)\n",
        "       # print(x.size(),y.size())\n",
        "        f3loss=torch.sqrt(loss3(x,y)/(256*32*24))\n",
        "\n",
        "        x=t1\n",
        "        y=t2\n",
        "        for f in self.features4:\n",
        "            x=f(x)\n",
        "            y=f(y)\n",
        "        #print(x.size(),y.size())\n",
        "        f4loss=torch.sqrt(loss4(x,y)/(512*16*12))\n",
        "\n",
        "        x=t1\n",
        "        y=t2\n",
        "        for f in self.features5:\n",
        "            x=f(x)\n",
        "            y=f(y)\n",
        "        #print(x.size(),y.size())\n",
        "        f5loss=torch.sqrt(loss5(x,y)/(512*8*6))\n",
        "        lamda=10\n",
        "        #print((f1loss+f2loss+f3loss+f4loss+f5loss))\n",
        "\n",
        "        #return (f1loss+f2loss+f3loss+f4loss+f5loss)*10\n",
        "        return (f1loss+f2loss+f3loss+f4loss+f5loss)*10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fhza6dAxPaOZ"
      },
      "source": [
        "##Encoder-Decoder,Discriminatorの初期化"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNJMxVvjVwdc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "430d868f-5643-4765-e766-e824db95b739"
      },
      "source": [
        "netG=EncoderDecoder(ngpu).to(device)\n",
        "netG.apply(init_weights)\n",
        "\n",
        "netD=Discriminator(ngpu).to(device)\n",
        "netD.apply(init_weights)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Discriminator(\n",
              "  (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
              "  (down1_1): Conv2d(6, 48, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
              "  (leaky): LeakyReLU(negative_slope=0.2)\n",
              "  (down1_2): Conv2d(48, 96, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
              "  (innorm1_2): InstanceNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
              "  (down1_3): Conv2d(96, 192, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
              "  (innorm1_3): InstanceNorm2d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
              "  (down1_4): Conv2d(192, 384, kernel_size=(4, 4), stride=(1, 1), padding=(2, 2))\n",
              "  (innorm1_4): InstanceNorm2d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
              "  (down1_5): Conv2d(384, 1, kernel_size=(4, 4), stride=(1, 1), padding=(2, 2))\n",
              "  (sigmoid): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SeKdlNQcKLFb"
      },
      "source": [
        "##Adam最適化＆損失関数"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xaQpTK6hKI9z"
      },
      "source": [
        "L1=nn.L1Loss()\n",
        "Lper=Vgg19Loss().to(device)\n",
        "Ladv=nn.BCELoss()\n",
        "tmapL1=nn.L1Loss()\n",
        "smapL1=nn.L1Loss()\n",
        "pmapL1=nn.L1Loss()\n",
        "\n",
        "real_label=1\n",
        "fake_label=0\n",
        "\n",
        "optimizernetG=optim.Adam(netG.parameters(),lr=lr,betas=(b1,b2))\n",
        "optimizernetD=optim.Adam(netD.parameters(),lr=lr,betas=(b1,b2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "teIykXZQoV_x"
      },
      "source": [
        "#ロード"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8uY1bobUM9kB"
      },
      "source": [
        "!unzip DiversityDesign_data.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkf9MT4G2GCv"
      },
      "source": [
        "!unzip segmentation.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OFG4PRlJ5PzB",
        "outputId": "17d60764-1124-46a1-e7d4-175359f65b15"
      },
      "source": [
        "%cd ..\r\n",
        "%cd .."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive\n",
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xoBOTMncoahK"
      },
      "source": [
        "PATHG='drive/My Drive/DiversityDesign_data/model/Encoder_Decoder.pth'\n",
        "#Unet = EncoderDecoder(ngpu).to(device)\n",
        "optimizernetG= optim.Adam(netG.parameters(),lr=lr,betas=(b1,b2))\n",
        "Ladv=nn.BCELoss()\n",
        "L1=nn.L1Loss()\n",
        "Lper=Vgg19Loss().to(device)\n",
        "\n",
        "checkpoint = torch.load(PATHG)\n",
        "netG.load_state_dict(checkpoint['model_state_dict'])\n",
        "optimizernetG.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "Ladv.load_state_dict(checkpoint['criterion1'])\n",
        "L1.load_state_dict(checkpoint['criterion2'])\n",
        "Lper.load_state_dict(checkpoint['criterion3'])\n",
        "epoch = checkpoint['epoch']\n",
        "#img_list=checkpoint['image']\n",
        "Sum_losses=checkpoint['Sum_losses']\n",
        "Generator_losses=checkpoint['Generator']\n",
        "kld_losses=checkpoint['kld']\n",
        "vgg_losses=checkpoint['Vgg']\n",
        "L1_losses=checkpoint[\"L1\"]\n",
        "judge1=checkpoint['judge1']\n",
        "judge2=checkpoint['judge2']\n",
        "judge3=checkpoint['judge3']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2zc5n9Rd-EIk"
      },
      "source": [
        "#システム\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TyWy6e36DK5M"
      },
      "source": [
        "##前処理"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pfs1JskfN4f1"
      },
      "source": [
        "!mkdir target\r\n",
        "!mkdir out\r\n",
        "!mkdir person\r\n",
        "!mkdir tops\r\n",
        "!mkdir pants\r\n",
        "!mkdir skirt\r\n",
        "!mkdir result\r\n",
        "!mkdir person/person\r\n",
        "!mkdir tops/mask\r\n",
        "!mkdir pants/mask\r\n",
        "!mkdir skirt/mask"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNDghwxWNsrX"
      },
      "source": [
        "**以下のコードを実行する前に、フォルダ\"target\"に人物画像を\"0.png\"として配置してください**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GyzS2qHzNUfE"
      },
      "source": [
        "!python drive/MyDrive/segmentation/simple_extractor.py --dataset lip --model-restore drive/MyDrive/segmentation/exp-schp-201908261155-lip.pth --input-dir target --output-dir out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zaD9R_Ji-gXu"
      },
      "source": [
        "name=0\n",
        "img1=cv2.imread(f\"out/{name}.png\")\n",
        "img2=cv2.imread(f\"target/{name}.png\")\n",
        "if img1.shape[0]>img1.shape[1]:\n",
        "    temp=int(img1.shape[0]/128) #[1]/96\n",
        "    w=temp*96\n",
        "    h=temp*128\n",
        "    if h>img1.shape[0]:\n",
        "      w=w/2\n",
        "      h=h/2\n",
        "\n",
        "    y2=img1.shape[0]-(img1.shape[0]-h)/2\n",
        "    y1=img1.shape[0]-((img1.shape[0]-h)/2)-h\n",
        "    if (y1-round(y1))==0.5:\n",
        "      y1=y1-0.5\n",
        "      y2=y2+0.5\n",
        "\n",
        "    x2=img1.shape[1]-(img1.shape[1]-w)/2\n",
        "    x1=img1.shape[1]-((img1.shape[1]-w)/2)-w\n",
        "    if (x1-round(x1))==0.5:\n",
        "      x1=x1+0.5\n",
        "      x2=x2+0.5\n",
        "    img1=img1[int(y1):int(y2),int(x1):int(x2),:]\n",
        "    img2=img2[int(y1):int(y2),int(x1):int(x2),:]\n",
        "    \n",
        "    \n",
        "    img1=cv2.resize(img1,(96,128))\n",
        "    img2=cv2.resize(img2,(96,128))\n",
        "\n",
        "elif img1.shape[0]<img1.shape[1]:\n",
        "    temp=int(img1.shape[0]/128)\n",
        "    w=temp*96\n",
        "    h=temp*128\n",
        "    if w>img1.shape[1]:\n",
        "      w=w/2\n",
        "      h=h/2\n",
        "\n",
        "    y2=img1.shape[0]-(img1.shape[0]-h)/2\n",
        "    y1=img1.shape[0]-((img1.shape[0]-h)/2)-h\n",
        "    if (y1-round(y1))==0.5:\n",
        "      y1=y1-0.5\n",
        "      y2=y2+0.5\n",
        "\n",
        "    x2=img1.shape[1]-(img1.shape[1]-w)/2\n",
        "    x1=img1.shape[1]-((img1.shape[1]-w)/2)-w\n",
        "    if (x1-round(x1))==0.5:\n",
        "      x1=x1+0.5\n",
        "      x2=x2+0.5\n",
        "    img1=img1[int(y1):int(y2),int(x1):int(x2),:]\n",
        "    img2=img2[int(y1):int(y2),int(x1):int(x2),:]\n",
        "    #print(img1.shape)\n",
        "   \n",
        "    img1=cv2.resize(img1,(96,128))\n",
        "    img2=cv2.resize(img2,(96,128))\n",
        "\n",
        "cv2_imshow(img1)\n",
        "cv2.imwrite(\"1.jpg\",img1)\n",
        "cv2.imwrite(f\"person/person/{name}.jpg\",img2)\n",
        "\n",
        "\n",
        "\n",
        "img1=img1.transpose(2,0,1)\n",
        "np.set_printoptions(threshold=np.inf)\n",
        "zero=np.zeros((1,img1.shape[1],img1.shape[2]))\n",
        "for i in range(img1.shape[1]):\n",
        "    for j in range(img1.shape[2]):\n",
        "      if img1[0][i][j]==128 and img1[1][i][j]==0 and img1[2][i][j]==128:\n",
        "        zero[0][i][j]=1\n",
        "  \n",
        "mask=zero.transpose(1,2,0)\n",
        "cv2.imwrite(f\"tops/mask/{name}.jpg\",mask*255)\n",
        "\n",
        "zero=np.zeros((1,img1.shape[1],img1.shape[2]))\n",
        "for i in range(img1.shape[1]):\n",
        "    for j in range(img1.shape[2]):\n",
        "      if img1[0][i][j]==0 and img1[1][i][j]==0 and img1[2][i][j]==192:\n",
        "        zero[0][i][j]=1\n",
        "  \n",
        "mask=zero.transpose(1,2,0)\n",
        "cv2.imwrite(f\"pants/mask/{name}.jpg\",mask*255)\n",
        "\n",
        "zero=np.zeros((1,img1.shape[1],img1.shape[2]))\n",
        "for i in range(img1.shape[1]):\n",
        "    for j in range(img1.shape[2]):\n",
        "      if img1[0][i][j]==128 and img1[1][i][j]==0 and img1[2][i][j]==64:\n",
        "        zero[0][i][j]=1\n",
        "  \n",
        "mask=zero.transpose(1,2,0)\n",
        "cv2.imwrite(f\"skirt/mask/{name}.jpg\",mask*255)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g7G_xWKv6CBN"
      },
      "source": [
        "**セグメンテーションマップが得られない場合は、フォルダ\"target\"を消去して別の画像で再度\"0.png\"として実行してください**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65O2MQ2kDSf_"
      },
      "source": [
        "##テスト"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rr77IkGKD-fr"
      },
      "source": [
        "dataroot4=\"pants\"\n",
        "dataroot8=\"skirt\"\n",
        "dataroot10=\"tops\"\n",
        "dataroot11=\"person\"\n",
        "num_thread=0\n",
        "batch_size=10\n",
        "num_epoch=15\n",
        "img_size=(128,96)\n",
        "lr=0.0002\n",
        "b1=0.5\n",
        "b2=0.999\n",
        "ngpu=1\n",
        "test_pants_mask_dataset=dset.ImageFolder(root=dataroot4,transform=transforms.Compose([transforms.Resize(img_size),transforms.Grayscale(),transforms.ToTensor(),]))\n",
        "test_skirt_mask_dataset=dset.ImageFolder(root=dataroot8,transform=transforms.Compose([transforms.Resize(img_size),transforms.Grayscale(),transforms.ToTensor(),]))\n",
        "test_tops_mask_dataset=dset.ImageFolder(root=dataroot10,transform=transforms.Compose([transforms.Resize(img_size),transforms.Grayscale(),transforms.ToTensor(),]))\n",
        "test_person_dataset=dset.ImageFolder(root=dataroot11,transform=transforms.Compose([transforms.Resize(img_size),transforms.ToTensor(),]))\n",
        "\n",
        "test_pants_mask_dataloader=torch.utils.data.DataLoader(test_pants_mask_dataset,batch_size=batch_size,shuffle=False,num_workers=num_thread)\n",
        "test_skirt_mask_dataloader=torch.utils.data.DataLoader(test_skirt_mask_dataset,batch_size=batch_size,shuffle=False,num_workers=num_thread)\n",
        "test_tops_mask_dataloader=torch.utils.data.DataLoader(test_tops_mask_dataset,batch_size=batch_size,shuffle=False,num_workers=num_thread)\n",
        "test_person_dataloader=torch.utils.data.DataLoader(test_person_dataset,batch_size=batch_size,shuffle=False,num_workers=num_thread)\n",
        "\n",
        "#device=torch.device(\"cuda:0\")\n",
        "print(len(test_person_dataset))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKoJELwQFU4J"
      },
      "source": [
        "n=100\n",
        "netG.eval()\n",
        "z=torch.randn(1,6,1,1).to(device)\n",
        "tops=False #topsの変化有無\n",
        "pants=True #pantsの変化有無\n",
        "skirt=False #skirtの変化有無\n",
        "for epoch in range(n):\n",
        "   \n",
        "   iter_person=iter(test_person_dataloader)\n",
        "\n",
        "   iter_tops_mask = iter(test_tops_mask_dataloader)\n",
        "   iter_pants_mask=iter(test_pants_mask_dataloader)\n",
        "   iter_skirt_mask= iter(test_skirt_mask_dataloader)\n",
        "\n",
        "   t1=time.time()\n",
        "   for tops_data in test_tops_mask_dataloader:\n",
        "        #0.バッチデータの取得     \n",
        "        \n",
        "        person_real_batch=next(iter_person)\n",
        "        tops_mask_real_batch=next(iter_tops_mask)\n",
        "        pants_mask_real_batch=next(iter_pants_mask)\n",
        "        skirt_mask_real_batch=next(iter_skirt_mask)\n",
        "       \n",
        "        person=person_real_batch[0].to(device)\n",
        "        tops_mask=tops_mask_real_batch[0].to(device)              #[][][][]\n",
        "        pants_mask=pants_mask_real_batch[0].to(device)      #[][][][]\n",
        "        skirt_mask=skirt_mask_real_batch[0].to(device)  \n",
        "\n",
        "        b_size = tops_mask.size(0)#バッチサイズを計算\n",
        "        #    \n",
        "        #データの連結\n",
        "        seg=torch.cat([tops_mask,pants_mask,skirt_mask],dim=1)\n",
        "        \n",
        "        #fakeを生成\n",
        "        if tops:\n",
        "          z[0,0,:,:]=torch.randn(1,1,1,1)\n",
        "          z[0,1,:,:]=torch.randn(1,1,1,1)\n",
        "        if pants:\n",
        "          z[0,2,:,:]=torch.randn(1,1,1,1)\n",
        "          z[0,3,:,:]=torch.randn(1,1,1,1)\n",
        "        if skirt:\n",
        "          z[0,4,:,:]=torch.randn(1,1,1,1)\n",
        "          z[0,5,:,:]=torch.randn(1,1,1,1)\n",
        "\n",
        "        fake=netG(_,seg,z,pre=True)\n",
        "        fake_image=overlay(person,fake[0],tops_mask,pants_mask,skirt_mask)\n",
        "   vutils.save_image(fake_image[0],f\"result/{name}_{epoch}.jpg\")\n",
        "   if (epoch+1)%5==0:\n",
        "    print(epoch+1)\n",
        "\n",
        "images=[]\n",
        "for i in range(n):\n",
        "  images.append(imageio.imread(f\"result/{name}_{i}.jpg\"))\n",
        "imageio.mimsave(f\"{name}.gif\",images,duration=0.35)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RvZ7f6-16ld_"
      },
      "source": [
        "**\"0.gif\"に多様な色の試着画像が保存されます**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GlCm6S-H58Yw"
      },
      "source": [
        "##削除"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HkystpM_S-9E"
      },
      "source": [
        "!rm \"0.gif\"\r\n",
        "%cd result/\r\n",
        "!rm *\r\n",
        "%cd .. \r\n",
        "!rm \"out/0.png\"\r\n",
        "!rm \"pants/mask/0.jpg\"\r\n",
        "!rm \"person/person/0.jpg\"\r\n",
        "!rm \"skirt/mask/0.jpg\"\r\n",
        "!rm \"tops/mask/0.jpg\"\r\n",
        "!rm \"target/0.png\""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}