{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": " DiversityDesign.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "UyrSIdKfbn6V",
        "FXhRBpIHlTAW",
        "jg5mpVkmAnpS",
        "QPblQfVyHaLf",
        "TgZcZhu5GHxd",
        "DhJAgd0FTr2d",
        "7Cjwy21ZT3ZV",
        "cyD0Ml9AT7ut",
        "Fhza6dAxPaOZ",
        "SeKdlNQcKLFb",
        "TCDnNYDR5E2z",
        "1C8x9ORbnRML",
        "teIykXZQoV_x"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7725855f4cd741d4ae8a677ab54554b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_192c25afb4584c3fbf168fae06116344",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8718b0199f654e26a2f40df94cb6ef51",
              "IPY_MODEL_877e0c11c8904682adcaaa0d7c1a8bb5"
            ]
          }
        },
        "192c25afb4584c3fbf168fae06116344": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8718b0199f654e26a2f40df94cb6ef51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_bf0eb450433a43698377e1eef3843a54",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 574673361,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 574673361,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_eef4e1f99901414388f20380fcb6ceca"
          }
        },
        "877e0c11c8904682adcaaa0d7c1a8bb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_04081f962c46480583c77edced8c627a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 548M/548M [00:12&lt;00:00, 47.9MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8c5ecc6a26104fb185efeb4820074ffa"
          }
        },
        "bf0eb450433a43698377e1eef3843a54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "eef4e1f99901414388f20380fcb6ceca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "04081f962c46480583c77edced8c627a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8c5ecc6a26104fb185efeb4820074ffa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UyrSIdKfbn6V"
      },
      "source": [
        "#ライブラリインポート\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJPhvzT0-Btt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "7725855f4cd741d4ae8a677ab54554b7",
            "192c25afb4584c3fbf168fae06116344",
            "8718b0199f654e26a2f40df94cb6ef51",
            "877e0c11c8904682adcaaa0d7c1a8bb5",
            "bf0eb450433a43698377e1eef3843a54",
            "eef4e1f99901414388f20380fcb6ceca",
            "04081f962c46480583c77edced8c627a",
            "8c5ecc6a26104fb185efeb4820074ffa"
          ]
        },
        "outputId": "d8e668b1-e1cc-434d-c704-830fb1e0adea"
      },
      "source": [
        "from __future__ import print_function\n",
        "#%matplotlib inline\n",
        "import argparse\n",
        "import os\n",
        "import cv2\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.utils as vutils\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "from IPython.display import HTML\n",
        "import time\n",
        "import subprocess as sp\n",
        "from datetime import datetime, timedelta, timezone\n",
        "import math\n",
        "from torchvision import datasets, models, transforms\n",
        "import torch.nn.functional as F\n",
        "import imageio\n",
        "vgg19 = models.vgg19(pretrained=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg19-dcbb9e9d.pth\" to /root/.cache/torch/hub/checkpoints/vgg19-dcbb9e9d.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7725855f4cd741d4ae8a677ab54554b7",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=574673361.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FXhRBpIHlTAW"
      },
      "source": [
        "#GPU使用時間と種類を表示"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8BydTpdanEi"
      },
      "source": [
        "res = sp.Popen([\"cat\", \"/proc/uptime\"], stdout=sp.PIPE)\n",
        "    # 単位はHour\n",
        "use_time = float(sp.check_output([\"awk\", \"{print $1 /60 /60 }\"], stdin=res.stdout).decode().replace(\"\\n\",\"\"))\n",
        "print(use_time)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FISVOABV_HpC"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C4Dpy1nkdKm5"
      },
      "source": [
        "#マウント"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYmiIYO883bl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd48afaf-a78c-41e1-d006-0a3480188dcc"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jg5mpVkmAnpS"
      },
      "source": [
        "#パラメータ定義"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "krU0QNbaAN56",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d288641-8c76-486f-c6cc-996a32479dbd"
      },
      "source": [
        "%cd drive/My\\ Drive\n",
        "dataroot3=\"DiversityDesign_data/color_pants\"\n",
        "dataroot4=\"DiversityDesign_data/verygood_smis_pants_mask\"\n",
        "dataroot7=\"DiversityDesign_data/color_skirt\"\n",
        "dataroot8=\"DiversityDesign_data/verygood_smis_skirt_mask\"\n",
        "dataroot9=\"DiversityDesign_data/color_tops\"\n",
        "dataroot10=\"DiversityDesign_data/verygood_smis_tops_mask\"\n",
        "dataroot11=\"DiversityDesign_data/color_persons\"\n",
        "num_thread=0\n",
        "batch_size=16\n",
        "num_epoch=15\n",
        "img_size=(128,96)\n",
        "lr=0.0002\n",
        "b1=0.5\n",
        "b2=0.999\n",
        "lamda1=6.85 \n",
        "lamda2=2.9\n",
        "lamda3=1.1\n",
        "ngpu=1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m9nIDpZQAu0K"
      },
      "source": [
        "#データのロード\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1VzZb04cmFua"
      },
      "source": [
        "!unzip DiversityDesign_data.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJ2dXvXwNXJO"
      },
      "source": [
        "!unzip color_data.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NaXy26DcAT5L"
      },
      "source": [
        "pants_dataset=dset.ImageFolder(root=dataroot3,transform=transforms.Compose([transforms.Resize(img_size),transforms.ToTensor(),]))\n",
        "pants_mask_dataset=dset.ImageFolder(root=dataroot4,transform=transforms.Compose([transforms.Resize(img_size),transforms.Grayscale(),transforms.ToTensor(),]))\n",
        "skirt_dataset=dset.ImageFolder(root=dataroot7,transform=transforms.Compose([transforms.Resize(img_size),transforms.ToTensor(),]))\n",
        "skirt_mask_dataset=dset.ImageFolder(root=dataroot8,transform=transforms.Compose([transforms.Resize(img_size),transforms.Grayscale(),transforms.ToTensor(),]))\n",
        "tops_dataset=dset.ImageFolder(root=dataroot9,transform=transforms.Compose([transforms.Resize(img_size),transforms.ToTensor(),]))\n",
        "tops_mask_dataset=dset.ImageFolder(root=dataroot10,transform=transforms.Compose([transforms.Resize(img_size),transforms.Grayscale(),transforms.ToTensor(),]))\n",
        "person_dataset=dset.ImageFolder(root=dataroot11,transform=transforms.Compose([transforms.Resize(img_size),transforms.ToTensor(),]))\n",
        "\n",
        "pants_dataloader=torch.utils.data.DataLoader(pants_dataset,batch_size=batch_size,shuffle=False,num_workers=num_thread)    \n",
        "pants_mask_dataloader=torch.utils.data.DataLoader(pants_mask_dataset,batch_size=batch_size,shuffle=False,num_workers=num_thread)\n",
        "skirt_dataloader=torch.utils.data.DataLoader(skirt_dataset,batch_size=batch_size,shuffle=False,num_workers=num_thread)\n",
        "skirt_mask_dataloader=torch.utils.data.DataLoader(skirt_mask_dataset,batch_size=batch_size,shuffle=False,num_workers=num_thread)\n",
        "tops_dataloader=torch.utils.data.DataLoader(tops_dataset,batch_size=batch_size,shuffle=False,num_workers=num_thread)\n",
        "tops_mask_dataloader=torch.utils.data.DataLoader(tops_mask_dataset,batch_size=batch_size,shuffle=False,num_workers=num_thread)\n",
        "person_dataloader=torch.utils.data.DataLoader(person_dataset,batch_size=batch_size,shuffle=False,num_workers=num_thread)\n",
        "\n",
        "device=torch.device(\"cuda:0\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QPblQfVyHaLf"
      },
      "source": [
        "#関数定義"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uKd7NWztUINU"
      },
      "source": [
        "##切り抜き"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_fX6wAW0HYZW"
      },
      "source": [
        "def overlay(p,f,tops,pants,skirt):\n",
        "  Mask=(tops+pants+skirt)\n",
        "  Mask=MaskTrans(Mask)\n",
        "  reverse=1-Mask\n",
        "  cutout1=p*reverse\n",
        "  cutout2=Mask*f\n",
        "  out=cutout1+cutout2\n",
        "  return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vjfpc9NNUMdR"
      },
      "source": [
        "##mask閾値"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fosipO__eToJ"
      },
      "source": [
        "def  MaskTrans(mask):\n",
        "  for i in range(mask.size(0)):\n",
        "    for j in range(mask.size(1)):\n",
        "      for k in range(mask.size(2)):\n",
        "        for l in range(mask.size(3)):\n",
        "          if mask[i][j][k][l]>0.6:\n",
        "            mask[i][j][k][l]=1\n",
        "          else:\n",
        "            mask[i][j][k][l]=0\n",
        "  return mask"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4uqbqrl-USsq"
      },
      "source": [
        "##重みの初期化"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uC9OpGtJOkg7"
      },
      "source": [
        "def init_weights(model):\n",
        "  if isinstance(model.modules,nn.Conv2d):\n",
        "      model.modules().weight.data.nomal_(0,0.002)\n",
        "      model.modules().bias.data.zero_()\n",
        "  if isinstance(model.modules,nn.ConvTranspose2d):\n",
        "      model.modules().weight.data.nomal_(0,0.002)\n",
        "      model.modules().bias.data.zero_()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bl7Qbmsri0Gm"
      },
      "source": [
        "##KLDloss\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29T88BldFUMg"
      },
      "source": [
        "def KLDloss(mu, logvar):\n",
        "  lamda=0.05\n",
        "  return lamda*(-0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TgZcZhu5GHxd"
      },
      "source": [
        "#クラス定義\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DhJAgd0FTr2d"
      },
      "source": [
        "##Encoder-Decoder\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWqoZBW-GMTS"
      },
      "source": [
        "class EncoderDecoder(nn.Module):\n",
        "  def __init__(self,ngpu):\n",
        "    super(EncoderDecoder,self).__init__()\n",
        "    self.ngpu=ngpu\n",
        "    #Encoder\n",
        "    df=3\n",
        "    self.down1_1=nn.Conv2d(3*df,32*df,3,2,1,bias=False,groups=3)\n",
        "    self.innorm1_1=nn.InstanceNorm2d(32*df,eps=1e-5)\n",
        "    self.Leaky=nn.LeakyReLU(0.2,inplace=True)\n",
        "    self.down1_2=nn.Conv2d(32*df,64*df,3,2,1,bias=False,groups=3)\n",
        "    self.innorm1_2=nn.InstanceNorm2d(64*df,eps=1e-5)\n",
        "    self.down1_3=nn.Conv2d(64*df,128*df,3,2,1,bias=False,groups=3)\n",
        "    self.innorm1_3=nn.InstanceNorm2d(128*df,eps=1e-5)\n",
        "    self.down1_4=nn.Conv2d(128*df,256*df,3,2,1,bias=False,groups=3)\n",
        "    self.innorm1_4=nn.InstanceNorm2d(256*df,eps=1e-5)\n",
        "    self.gamma=nn.Conv2d(256*df,2*df,(8,6),1,0,bias=False,groups=3)\n",
        "    self.beta=nn.Conv2d(256*df,2*df,(8,6),1,0,bias=False,groups=3)\n",
        "    \n",
        "    #Decoder\n",
        "    self.down1_0=nn.Conv2d(2*df,256*df,3,1,1,groups=3)\n",
        "    self.relu=nn.ReLU()\n",
        "    self.leaky=nn.LeakyReLU(0.2,inplace=True)\n",
        "    self.batch2_1=nn.BatchNorm2d(256*df,eps=1e-5,affine=False)\n",
        "    self.pool2_1=nn.MaxPool2d(16)\n",
        "    self.share2_1=nn.Conv2d(df*1,16*df,3,1,1,groups=3)\n",
        "    self.gamma2_1=nn.Conv2d(16*df,256*df,3,1,1,groups=3)\n",
        "    self.beta2_1=nn.Conv2d(16*df,256*df,3,1,1,groups=3)\n",
        "    self.gconv2_1=nn.Conv2d(256*df,256*df,3,1,1,groups=3)\n",
        "    self.up2_1=nn.Upsample(scale_factor=2,mode=\"nearest\")\n",
        "    self.batch3_1=nn.BatchNorm2d(256*df,eps=1e-5,affine=False)\n",
        "    self.pool3_1=nn.MaxPool2d(8)\n",
        "    self.share3_1=nn.Conv2d(1*df,16*df,3,1,1,groups=3)\n",
        "    self.gamma3_1=nn.Conv2d(16*df,256*df,3,1,1,groups=3)\n",
        "    self.beta3_1=nn.Conv2d(16*df,256*df,3,1,1,groups=3)\n",
        "    self.gconv3_1=nn.Conv2d(256*df,128*df,3,1,1,groups=3)\n",
        "    self.up3_1=nn.Upsample(scale_factor=2,mode=\"nearest\")\n",
        "    self.batch4_1=nn.BatchNorm2d(128*df,eps=1e-5,affine=False)\n",
        "    self.pool4_1=nn.MaxPool2d(4)\n",
        "    self.share4_1=nn.Conv2d(1*df,16*df,3,1,1,groups=3)\n",
        "    self.gamma4_1=nn.Conv2d(16*df,128*df,3,1,1,groups=3)\n",
        "    self.beta4_1=nn.Conv2d(16*df,128*df,3,1,1,groups=3)\n",
        "    self.gconv4_1=nn.Conv2d(128*df,64*df,3,1,1,groups=3)\n",
        "    self.up4_1=nn.Upsample(scale_factor=4,mode=\"nearest\")\n",
        "    self.smooth4_1=nn.Conv2d(64*df,64*df,3,1,1,groups=3)\n",
        "    self.batch5_1=nn.BatchNorm2d(64*df,eps=1e-5,affine=False)\n",
        "    self.pool5_1=nn.MaxPool2d(1)\n",
        "    self.share5_1=nn.Conv2d(1*df,16*df,3,1,1,groups=3)\n",
        "    self.gamma5_1=nn.Conv2d(16*df,64*df,3,1,1,groups=3)\n",
        "    self.beta5_1=nn.Conv2d(16*df,64*df,3,1,1,groups=3)\n",
        "    self.gconv5_1=nn.Conv2d(64*df,32*df,3,1,1,groups=3)\n",
        "    self.pbatch=nn.BatchNorm2d(32*df,eps=1e-5,affine=False)\n",
        "    self.ppool=nn.MaxPool2d(1)\n",
        "    self.pshare=nn.Conv2d(1*df,16*df,3,1,1,groups=3)\n",
        "    self.pgamma=nn.Conv2d(16*df,32*df,3,1,1,groups=3)\n",
        "    self.pbeta=nn.Conv2d(16*df,32*df,3,1,1,groups=3)\n",
        "    self.pgconv=nn.Conv2d(32*df,20*df,3,1,1,groups=3)\n",
        "    self.lastconv=nn.Conv2d(20*df,3,1,1,0)\n",
        "    self.sigmoid=nn.Sigmoid()\n",
        "\n",
        "  def Encoder(self,input): \n",
        "    down1_1=self.down1_1(input)\n",
        "    innorm1_1=self.innorm1_1(down1_1)\n",
        "\n",
        "    leaky1_2=self.Leaky(innorm1_1)\n",
        "    down1_2=self.down1_2(leaky1_2)\n",
        "    innorm1_2=self.innorm1_2(down1_2)\n",
        "  \n",
        "    leaky1_3=self.Leaky(innorm1_2)\n",
        "    down1_3=self.down1_3(leaky1_3)\n",
        "    innorm1_3=self.innorm1_3(down1_3)\n",
        "    \n",
        "    leaky1_4=self.Leaky(innorm1_3)\n",
        "    down1_4=self.down1_4(leaky1_4)\n",
        "    innorm1_4=self.innorm1_4(down1_4)\n",
        "    \n",
        "    leaky1_5=self.Leaky(innorm1_4)\n",
        "    gamma=self.gamma(leaky1_5)\n",
        "    beta=self.beta(leaky1_5)\n",
        "\n",
        "    return gamma,beta\n",
        "\n",
        "  def Decoder(self,z,seg,test=False): \n",
        "    down1_0=self.down1_0(z)\n",
        "\n",
        "    batch2_1=self.batch2_1(down1_0)\n",
        "    share2_1=self.relu(self.share2_1(self.pool2_1(seg)))\n",
        "    gamma2_1=self.gamma2_1(share2_1)\n",
        "    beta2_1=self.beta2_1(share2_1)\n",
        "    temp2_1=(batch2_1*gamma2_1)+beta2_1\n",
        "    out2_1=self.up2_1(self.gconv2_1(self.leaky(temp2_1)))\n",
        "  \n",
        "    batch3_1=self.batch3_1(out2_1)\n",
        "    share3_1=self.relu(self.share3_1(self.pool3_1(seg)))\n",
        "    gamma3_1=self.gamma3_1(share3_1)\n",
        "    beta3_1=self.beta3_1(share3_1)\n",
        "    temp3_1=(batch3_1*gamma3_1)+beta3_1\n",
        "    out3_1=self.up3_1(self.gconv3_1(self.leaky(temp3_1)))\n",
        "  \n",
        "    batch4_1=self.batch4_1(out3_1)\n",
        "    share4_1=self.relu(self.share4_1(self.pool4_1(seg)))\n",
        "    gamma4_1=self.gamma4_1(share4_1)\n",
        "    beta4_1=self.beta4_1(share4_1)\n",
        "    temp4_1=(batch4_1*gamma4_1)+beta4_1\n",
        "    out4_1=self.up4_1(self.gconv4_1(self.leaky(temp4_1)))\n",
        "    out4_1=self.smooth4_1(out4_1)\n",
        "  \n",
        "    batch5_1=self.batch5_1(out4_1)\n",
        "    share5_1=self.relu(self.share5_1(self.pool5_1(seg)))\n",
        "    gamma5_1=self.gamma5_1(share5_1)\n",
        "    beta5_1=self.beta5_1(share5_1)\n",
        "    temp5_1=(batch5_1*gamma5_1)+beta5_1\n",
        "    out5_1=self.gconv5_1(self.leaky(temp5_1))\n",
        "    \n",
        "    batch=self.pbatch(out5_1)\n",
        "    share=self.relu(self.pshare(self.ppool(seg)))\n",
        "    gamma=self.pgamma(share)\n",
        "    beta=self.pbeta(share)\n",
        "    temp=(batch*gamma)+beta\n",
        "    out=self.pgconv(self.leaky(temp))\n",
        "    last=self.leaky(out)   \n",
        "    out5=self.sigmoid(self.lastconv(last))\n",
        "\n",
        "    return out5,last\n",
        "\n",
        "\n",
        "  def reparameterize(self,mu, logvar):\n",
        "      std = torch.exp(0.5 * logvar) \n",
        "      eps = torch.randn_like(std)/4\n",
        "      return eps.mul(std) + mu\n",
        "\n",
        "\n",
        "  def forward(self,input,seg,Z,test=False,pre=False,encodeonly=False):\n",
        "    if not test and not pre and not encodeonly:\n",
        "      mu,logvar=self.Encoder(input)\n",
        "      z=self.reparameterize(mu,logvar)\n",
        "      fake,last=self.Decoder(z,seg)\n",
        "      return fake,mu,logvar,z,last\n",
        "    \n",
        "    elif pre==True:\n",
        "      fake,_=self.Decoder(Z,seg,test=True)\n",
        "      return fake\n",
        "\n",
        "    elif encodeonly==True:\n",
        "      mu,logvar=self.Encoder(input)\n",
        "      z=self.reparameterize(mu,logvar)\n",
        "      return z,mu,logvar\n",
        "\n",
        "    else:\n",
        "      z=torch.randn((1,6,1,1)).to(device)\n",
        "      z=z.repeat(seg.size(0),1,1,1)\n",
        "      fake,_=self.Decoder(z,seg,test=True)\n",
        "      return fake,z"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Cjwy21ZT3ZV"
      },
      "source": [
        "##Discriminator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4EQl2xjyA5A3"
      },
      "source": [
        "class Discriminator(nn.Module):\n",
        "  def __init__(self,ngpu):    \n",
        "    super(Discriminator,self).__init__()\n",
        "    self.ngpu=ngpu\n",
        "    df=3\n",
        "    dc=df+3\n",
        "    \n",
        "    self.pool=nn.AvgPool2d(2)\n",
        "    self.down1_1=nn.Conv2d(dc,8*dc,4,2,2)\n",
        "    self.leaky=nn.LeakyReLU(0.2)\n",
        "    self.down1_2=nn.Conv2d(8*dc,16*dc,4,2,2)\n",
        "    self.innorm1_2=nn.InstanceNorm2d(16*dc)\n",
        "    self.down1_3=nn.Conv2d(16*dc,32*dc,4,2,2)\n",
        "    self.innorm1_3=nn.InstanceNorm2d(32*dc)\n",
        "    self.down1_4=nn.Conv2d(32*dc,64*dc,4,1,2)\n",
        "    self.innorm1_4=nn.InstanceNorm2d(64*dc)\n",
        "    self.down1_5=nn.Conv2d(64*dc,1,4,1,2)\n",
        "    self.sigmoid=nn.Sigmoid()\n",
        "\n",
        "  def Discriminator(self,image,seg): \n",
        "    featmap=[]\n",
        "    data=torch.cat([image,seg],dim=1)\n",
        "    \n",
        "    pool1_1=self.pool(data)\n",
        "    down1_1=self.down1_1(pool1_1)\n",
        "    leaky1_1=self.leaky(down1_1)\n",
        "    featmap.append(leaky1_1)\n",
        "   \n",
        "    down1_2=self.down1_2(leaky1_1)\n",
        "    innorm1_2=self.innorm1_2(down1_2)\n",
        "    leaky1_2=self.leaky(innorm1_2)\n",
        "    featmap.append(leaky1_2)\n",
        "  \n",
        "    down1_3=self.down1_3(leaky1_2)\n",
        "    innorm1_3=self.innorm1_3(down1_3)\n",
        "    leaky1_3=self.leaky(innorm1_3)\n",
        "    featmap.append(leaky1_3)\n",
        "    \n",
        "    down1_4=self.down1_4(leaky1_3)\n",
        "    innorm1_4=self.innorm1_4(down1_4)\n",
        "    leaky1_4=self.leaky(innorm1_4)\n",
        "    featmap.append(leaky1_4)\n",
        "\n",
        "    down1_5=self.down1_5(leaky1_4)\n",
        "\n",
        "    return self.sigmoid(down1_5),featmap"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cyD0Ml9AT7ut"
      },
      "source": [
        "##知覚損失(/有)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXrTi7USTXXN"
      },
      "source": [
        "class Vgg19Loss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Vgg19Loss, self).__init__()\n",
        "        features1=list(vgg19.features)[:3]\n",
        "        features2=list(vgg19.features)[:8]\n",
        "        features3=list(vgg19.features)[:13]\n",
        "        features4=list(vgg19.features)[:22]\n",
        "        features5=list(vgg19.features)[:31]\n",
        "        self.features1=nn.ModuleList(features1).eval()\n",
        "        self.features2=nn.ModuleList(features2).eval()\n",
        "        self.features3=nn.ModuleList(features3).eval()\n",
        "        self.features4=nn.ModuleList(features4).eval()\n",
        "        self.features5=nn.ModuleList(features5).eval()\n",
        "\n",
        "    def forward(self,x,y):\n",
        "        lamda=5\n",
        "        t1=x\n",
        "        t2=y\n",
        "        loss1=nn.MSELoss()\n",
        "        loss2=nn.MSELoss()\n",
        "        loss3=nn.MSELoss()\n",
        "        loss4=nn.MSELoss()\n",
        "        loss5=nn.MSELoss()\n",
        "\n",
        "        for f in self.features1:\n",
        "            x=f(x)\n",
        "            y=f(y)\n",
        "        f1loss=torch.sqrt(loss1(x,y)/(64*128*96))\n",
        "      \n",
        "        x=t1\n",
        "        y=t2\n",
        "        for f in self.features2:\n",
        "            x=f(x)\n",
        "            y=f(y)\n",
        "        f2loss=torch.sqrt(loss2(x,y)/(128*64*48))\n",
        "\n",
        "        x=t1\n",
        "        y=t2\n",
        "        for f in self.features3:\n",
        "            x=f(x)\n",
        "            y=f(y)\n",
        "        f3loss=torch.sqrt(loss3(x,y)/(256*32*24))\n",
        "\n",
        "        x=t1\n",
        "        y=t2\n",
        "        for f in self.features4:\n",
        "            x=f(x)\n",
        "            y=f(y)\n",
        "        f4loss=torch.sqrt(loss4(x,y)/(512*16*12))\n",
        "\n",
        "        x=t1\n",
        "        y=t2\n",
        "        for f in self.features5:\n",
        "            x=f(x)\n",
        "            y=f(y)\n",
        "        f5loss=torch.sqrt(loss5(x,y)/(512*8*6))\n",
        "  \n",
        "        return (f1loss+f2loss+f3loss+f4loss+f5loss)*lamda"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fhza6dAxPaOZ"
      },
      "source": [
        "#Encoder-Decoder,Discriminatorの初期化"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNJMxVvjVwdc"
      },
      "source": [
        "netG=EncoderDecoder(ngpu).to(device)\n",
        "netG.apply(init_weights)\n",
        "netD=Discriminator(ngpu).to(device)\n",
        "netD.apply(init_weights)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SeKdlNQcKLFb"
      },
      "source": [
        "#Adam最適化＆損失関数"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xaQpTK6hKI9z"
      },
      "source": [
        "L1=nn.L1Loss()\n",
        "Lper=Vgg19Loss().to(device)\n",
        "Ladv=nn.BCELoss()\n",
        "tmapL1=nn.L1Loss()\n",
        "smapL1=nn.L1Loss()\n",
        "pmapL1=nn.L1Loss()\n",
        "\n",
        "real_label=1\n",
        "fake_label=0\n",
        "\n",
        "optimizernetG=optim.Adam(netG.parameters(),lr=lr,betas=(b1,b2))\n",
        "optimizernetD=optim.Adam(netD.parameters(),lr=lr,betas=(b1,b2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "24roAR13PACu"
      },
      "source": [
        "#学習"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4cChhVcP3r7M"
      },
      "source": [
        "Generator_losses=[]\n",
        "Discriminator_losses = []\n",
        "Sum_losses = []\n",
        "kld_losses=[]\n",
        "vgg_losses=[]\n",
        "feat_losses=[]\n",
        "L1_losses=[]\n",
        "judge1=[]\n",
        "judge2=[]\n",
        "judge3=[]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYmt1eByxvEp"
      },
      "source": [
        "i=0\n",
        "netG.train()\n",
        "t1=time.time()\n",
        "for epoch in range(num_epoch):\n",
        "   iter_tops = iter(tops_dataloader)\n",
        "   iter_pants=iter(pants_dataloader)\n",
        "   iter_skirt = iter(skirt_dataloader)\n",
        "   iter_person=iter(person_dataloader)\n",
        "\n",
        "   iter_tops_mask = iter(tops_mask_dataloader)\n",
        "   iter_pants_mask=iter(pants_mask_dataloader)\n",
        "   iter_skirt_mask= iter(skirt_mask_dataloader)\n",
        "\n",
        "   for tops_data in tops_dataloader:\n",
        "\n",
        "        tops_real_batch=next(iter_tops)\n",
        "        pants_real_batch=next(iter_pants)\n",
        "        skirt_real_batch=next(iter_skirt)\n",
        "        person_real_batch=next(iter_person)\n",
        "        tops_mask_real_batch=next(iter_tops_mask)\n",
        "        pants_mask_real_batch=next(iter_pants_mask)\n",
        "        skirt_mask_real_batch=next(iter_skirt_mask)\n",
        "       \n",
        "        tops=tops_real_batch[0].to(device)              \n",
        "        pants=pants_real_batch[0].to(device)      \n",
        "        skirt=skirt_real_batch[0].to(device)  \n",
        "        person=person_real_batch[0].to(device)\n",
        "        tops_mask=tops_mask_real_batch[0].to(device)              \n",
        "        pants_mask=pants_mask_real_batch[0].to(device)      \n",
        "        skirt_mask=skirt_mask_real_batch[0].to(device) \n",
        "\n",
        "        tmask=tops_mask.repeat(1,20,1,1) \n",
        "        pmask=pants_mask.repeat(1,20,1,1)\n",
        "        smask=skirt_mask.repeat(1,20,1,1)\n",
        "        b_size = tops.size(0)\n",
        "        \n",
        "        input=torch.cat([tops,pants,skirt],dim=1)\n",
        "        seg=torch.cat([tops_mask,pants_mask,skirt_mask],dim=1)\n",
        "        \n",
        "        for j in range(1):\n",
        "          \n",
        "          fake,mu,logvar,_,map=netG(input,seg,_)\n",
        "    \n",
        "          #Discriminator\n",
        "          netD.zero_grad()\n",
        "          item=tops+pants+skirt\n",
        "          \n",
        "          pre_t,featmap_t=netD.Discriminator(item,seg)\n",
        "          judge1.append(pre_t.mean())\n",
        "          label = torch.full(pre_t.size(), fill_value=real_label,dtype=torch.float32,device=device)\n",
        "          D_loss_t = Ladv(pre_t,label)\n",
        "          D_loss_t.backward()\n",
        "\n",
        "          pre_f,featmap_f=netD.Discriminator(fake.detach(),seg)\n",
        "          judge2.append(pre_f.mean())\n",
        "          label.fill_(fake_label)\n",
        "          D_loss_f= Ladv(pre_f,label)\n",
        "          D_loss_f.backward()\n",
        "          D_loss=D_loss_t+D_loss_f\n",
        "          optimizernetD.step()\n",
        "          \n",
        "          #Generator\n",
        "          if i%1==0:\n",
        "            netG.zero_grad()\n",
        "            label.fill_(real_label)\n",
        "            pre_Gf,featmap_f=netD.Discriminator(fake,seg)\n",
        "\n",
        "            G_loss_f = Ladv(pre_Gf,label)\n",
        "            pre_t,featmap_t=netD.Discriminator(item,seg)\n",
        "            kld_loss=KLDloss(mu,logvar)\n",
        "            L1_loss=L1(fake,item)\n",
        "            vgg_loss=Lper(item,fake)     \n",
        "            tmap_loss=tmapL1(map[:,:20,:,:],tmask)*lamda1 \n",
        "            pmap_loss=pmapL1(map[:,20:40,:,:],pmask)*lamda2  \n",
        "            smap_loss=smapL1(map[:,40:60,:,:],smask)*lamda3  \n",
        "\n",
        "            kld_losses.append(kld_loss.detach())\n",
        "            vgg_losses.append(vgg_loss.detach())\n",
        "            L1_losses.append(L1_loss.detach())\n",
        "        \n",
        "            G_loss=G_loss_f+kld_loss+L1_loss+(vgg_loss*3)+tmap_loss+pmap_loss+smap_loss\n",
        "            G_loss.backward()\n",
        "            optimizernetG.step()\n",
        "\n",
        "          judge3.append(pre_Gf.mean())\n",
        "          Sum_losses.append(G_loss.detach())\n",
        "          Generator_losses.append(G_loss_f.detach())\n",
        "          Discriminator_losses.append(D_loss.detach())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kdJ6hPmXsRPJ"
      },
      "source": [
        "#テスト\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rdsOKU9Jai0b"
      },
      "source": [
        "##再構築テスト\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBo08dfksUvr"
      },
      "source": [
        "%cd drive/My\\ Drive\n",
        "dataroot3=\"DiversityDesign_data/abs_pants\"\n",
        "dataroot4=\"DiversityDesign_data/test_smis_pants_mask\"\n",
        "dataroot7=\"DiversityDesign_data/abs_skirt\"\n",
        "dataroot8=\"DiversityDesign_data/test_smis_skirt_mask\"\n",
        "dataroot9=\"DiversityDesign_data/abs_tops\"\n",
        "dataroot10=\"DiversityDesign_data/test_smis_tops_mask\"\n",
        "dataroot11=\"DiversityDesign_data/abs_person\"\n",
        "\n",
        "num_thread=0\n",
        "batch_size=10\n",
        "num_epoch=15\n",
        "img_size=(128,96)\n",
        "lr=0.0002\n",
        "b1=0.5\n",
        "b2=0.999\n",
        "ngpu=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6VhYfZWsqTz"
      },
      "source": [
        "test_pants_dataset=dset.ImageFolder(root=dataroot3,transform=transforms.Compose([transforms.Resize(img_size),transforms.ToTensor(),]))\n",
        "test_pants_mask_dataset=dset.ImageFolder(root=dataroot4,transform=transforms.Compose([transforms.Resize(img_size),transforms.Grayscale(),transforms.ToTensor(),]))\n",
        "test_skirt_dataset=dset.ImageFolder(root=dataroot7,transform=transforms.Compose([transforms.Resize(img_size),transforms.ToTensor(),]))\n",
        "test_skirt_mask_dataset=dset.ImageFolder(root=dataroot8,transform=transforms.Compose([transforms.Resize(img_size),transforms.Grayscale(),transforms.ToTensor(),]))\n",
        "test_tops_dataset=dset.ImageFolder(root=dataroot9,transform=transforms.Compose([transforms.Resize(img_size),transforms.ToTensor(),]))\n",
        "test_tops_mask_dataset=dset.ImageFolder(root=dataroot10,transform=transforms.Compose([transforms.Resize(img_size),transforms.Grayscale(),transforms.ToTensor(),]))\n",
        "test_person_dataset=dset.ImageFolder(root=dataroot11,transform=transforms.Compose([transforms.Resize(img_size),transforms.ToTensor(),]))\n",
        "\n",
        "test_pants_dataloader=torch.utils.data.DataLoader(test_pants_dataset,batch_size=batch_size,shuffle=False,num_workers=num_thread)    \n",
        "test_pants_mask_dataloader=torch.utils.data.DataLoader(test_pants_mask_dataset,batch_size=batch_size,shuffle=False,num_workers=num_thread)\n",
        "test_skirt_dataloader=torch.utils.data.DataLoader(test_skirt_dataset,batch_size=batch_size,shuffle=False,num_workers=num_thread)\n",
        "test_skirt_mask_dataloader=torch.utils.data.DataLoader(test_skirt_mask_dataset,batch_size=batch_size,shuffle=False,num_workers=num_thread)\n",
        "test_tops_dataloader=torch.utils.data.DataLoader(test_tops_dataset,batch_size=batch_size,shuffle=False,num_workers=num_thread)\n",
        "test_tops_mask_dataloader=torch.utils.data.DataLoader(test_tops_mask_dataset,batch_size=batch_size,shuffle=False,num_workers=num_thread)\n",
        "test_person_dataloader=torch.utils.data.DataLoader(test_person_dataset,batch_size=batch_size,shuffle=False,num_workers=num_thread)\n",
        "\n",
        "device=torch.device(\"cuda:0\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZkMCdTFtQZ_"
      },
      "source": [
        "images=[]\n",
        "i=0\n",
        "bre=0\n",
        "end=0#終了バッチの設定 0~4\n",
        "netG.eval()\n",
        "for epoch in range(1):\n",
        "\n",
        "   iter_tops = iter(test_tops_dataloader)\n",
        "   iter_pants=iter(test_pants_dataloader)\n",
        "   iter_skirt = iter(test_skirt_dataloader)\n",
        "   iter_person=iter(test_person_dataloader)\n",
        "\n",
        "   iter_tops_mask = iter(test_tops_mask_dataloader)\n",
        "   iter_pants_mask=iter(test_pants_mask_dataloader)\n",
        "   iter_skirt_mask= iter(test_skirt_mask_dataloader)\n",
        "  \n",
        "\n",
        "   t1=time.time()\n",
        "   for tops_data in test_tops_dataloader:\n",
        "        #0.バッチデータの取得     \n",
        "        tops_real_batch=next(iter_tops)\n",
        "        pants_real_batch=next(iter_pants)\n",
        "        skirt_real_batch=next(iter_skirt)\n",
        "        person_real_batch=next(iter_person)\n",
        "\n",
        "        tops_mask_real_batch=next(iter_tops_mask)\n",
        "        pants_mask_real_batch=next(iter_pants_mask)\n",
        "        skirt_mask_real_batch=next(iter_skirt_mask)\n",
        "  \n",
        "       \n",
        "        tops=tops_real_batch[0].to(device)              #[][][][]\n",
        "        pants=pants_real_batch[0].to(device)      #[][][][]\n",
        "        skirt=skirt_real_batch[0].to(device)  \n",
        "        person=person_real_batch[0].to(device)\n",
        "\n",
        "        tops_mask=tops_mask_real_batch[0].to(device)              #[][][][]\n",
        "        pants_mask=pants_mask_real_batch[0].to(device)      #[][][][]\n",
        "        skirt_mask=skirt_mask_real_batch[0].to(device)  \n",
        "       \n",
        "\n",
        "        b_size = tops.size(0)#バッチサイズを計算\n",
        "        \n",
        "        \n",
        "        #データの連結\n",
        "        input=torch.cat([tops,pants,skirt],dim=1)\n",
        "        seg=torch.cat([tops_mask,pants_mask,skirt_mask],dim=1)\n",
        "        \n",
        "        #fakeを生成\n",
        "        if bre==end:\n",
        "            z,mu,logvar=netG(input,_,_,encodeonly=True)\n",
        "            fake=netG(_,seg,z,pre=True)\n",
        "            fake_image=overlay(person,fake,tops_mask,pants_mask,skirt_mask)\n",
        "            true_image=overlay(person,tops+pants+skirt,tops_mask,pants_mask,skirt_mask)\n",
        "            images.append(fake_image.detach())\n",
        "            break      \n",
        "        bre+=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5G0BG-n4z07k"
      },
      "source": [
        "plt.figure(figsize=(30,30))\n",
        "plt.imshow(np.transpose(vutils.make_grid(fake_image.detach().to(device)[:10], padding=2, normalize=True).cpu(),(1,2,0)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4B-etaz0Y10Z"
      },
      "source": [
        "plt.figure(figsize=(30,30))\r\n",
        "plt.imshow(np.transpose(vutils.make_grid(true_image.detach().to(device)[:10], padding=2, normalize=True).cpu(),(1,2,0)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLiroFvNarAd"
      },
      "source": [
        "##多様性テスト"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L7_iyfm9awTf"
      },
      "source": [
        "%cd drive/My\\ Drive\n",
        "\n",
        "dataroot3=\"DiversityDesign_data/yellow_pants\"\n",
        "dataroot4=\"DiversityDesign_data/test_smis_pants_mask\"\n",
        "dataroot7=\"DiversityDesign_data/yellow_skirt\"\n",
        "dataroot8=\"DiversityDesign_data/test_smis_skirt_mask\"\n",
        "dataroot9=\"DiversityDesign_data/yellow_tops\"\n",
        "dataroot10=\"DiversityDesign_data/test_smis_tops_mask\"\n",
        "dataroot11=\"DiversityDesign_data/abs_person\"\n",
        "num_thread=0\n",
        "batch_size=1\n",
        "num_epoch=15\n",
        "img_size=(128,96)\n",
        "lr=0.0002\n",
        "b1=0.5\n",
        "b2=0.999\n",
        "ngpu=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTezIBH-bOtv"
      },
      "source": [
        "test_pants_dataset=dset.ImageFolder(root=dataroot3,transform=transforms.Compose([transforms.Resize(img_size),transforms.ToTensor(),]))\n",
        "test_pants_mask_dataset=dset.ImageFolder(root=dataroot4,transform=transforms.Compose([transforms.Resize(img_size),transforms.Grayscale(),transforms.ToTensor(),]))\n",
        "test_skirt_dataset=dset.ImageFolder(root=dataroot7,transform=transforms.Compose([transforms.Resize(img_size),transforms.ToTensor(),]))\n",
        "test_skirt_mask_dataset=dset.ImageFolder(root=dataroot8,transform=transforms.Compose([transforms.Resize(img_size),transforms.Grayscale(),transforms.ToTensor(),]))\n",
        "test_tops_dataset=dset.ImageFolder(root=dataroot9,transform=transforms.Compose([transforms.Resize(img_size),transforms.ToTensor(),]))\n",
        "test_tops_mask_dataset=dset.ImageFolder(root=dataroot10,transform=transforms.Compose([transforms.Resize(img_size),transforms.Grayscale(),transforms.ToTensor(),]))\n",
        "test_person_dataset=dset.ImageFolder(root=dataroot11,transform=transforms.Compose([transforms.Resize(img_size),transforms.ToTensor(),]))\n",
        "\n",
        "test_pants_dataloader=torch.utils.data.DataLoader(test_pants_dataset,batch_size=batch_size,shuffle=False,num_workers=num_thread)    \n",
        "test_pants_mask_dataloader=torch.utils.data.DataLoader(test_pants_mask_dataset,batch_size=batch_size,shuffle=False,num_workers=num_thread)\n",
        "test_skirt_dataloader=torch.utils.data.DataLoader(test_skirt_dataset,batch_size=batch_size,shuffle=False,num_workers=num_thread)\n",
        "test_skirt_mask_dataloader=torch.utils.data.DataLoader(test_skirt_mask_dataset,batch_size=batch_size,shuffle=False,num_workers=num_thread)\n",
        "test_tops_dataloader=torch.utils.data.DataLoader(test_tops_dataset,batch_size=batch_size,shuffle=False,num_workers=num_thread)\n",
        "test_tops_mask_dataloader=torch.utils.data.DataLoader(test_tops_mask_dataset,batch_size=batch_size,shuffle=False,num_workers=num_thread)\n",
        "test_person_dataloader=torch.utils.data.DataLoader(test_person_dataset,batch_size=batch_size,shuffle=False,num_workers=num_thread)\n",
        "\n",
        "device=torch.device(\"cuda:0\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gbcq-Ki7bQTe"
      },
      "source": [
        "netG.eval()\n",
        "for epoch in range(1):\n",
        "   iter_tops = iter(test_tops_dataloader)\n",
        "   iter_pants=iter(test_pants_dataloader)\n",
        "   iter_skirt = iter(test_skirt_dataloader)\n",
        "\n",
        "   for tops_data in test_tops_dataloader:\n",
        "        #0.バッチデータの取得     \n",
        "        tops_real_batch=next(iter_tops)\n",
        "        pants_real_batch=next(iter_pants)\n",
        "        skirt_real_batch=next(iter_skirt)\n",
        "       \n",
        "        tops=tops_real_batch[0].to(device)              #[][][][]\n",
        "        pants=pants_real_batch[0].to(device)      #[][][][]\n",
        "        skirt=skirt_real_batch[0].to(device)  \n",
        "\n",
        "        b_size = tops.size(0)#バッチサイズを計算\n",
        "          \n",
        "        #データの連結\n",
        "        input=torch.cat([tops,pants,skirt],dim=1)\n",
        "       \n",
        "        #fakeを生成\n",
        "        z,mu,logvar=netG(input,_,_,encodeonly=True)\n",
        "        print(z.size())\n",
        "        print(z.mean())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2scOMhIOmrM"
      },
      "source": [
        "z=z.repeat(batch_size,1,1,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jq-BW0_sROzA"
      },
      "source": [
        "n=3\n",
        "z[:,0,:,:]=-n\n",
        "z[:,1,:,:]=n\n",
        "z[:,2,:,:]=0\n",
        "z[:,3,:,:]=0\n",
        "z[:,4,:,:]=0\n",
        "z[:,5,:,:]=0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ribsUClKe4Ut"
      },
      "source": [
        "images=[]\n",
        "i=0\n",
        "count=0\n",
        "t=7\n",
        "for i in range(n*2*2):\n",
        "  z[:,1,:,:]=z[:,1,:,:]-0.5\n",
        "  z[:,0,:,:]=-n\n",
        "  for epoch in range(n*2*2):\n",
        "    z[:,0,:,:]=z[:,0,:,:]+0.5\n",
        "    iter_person=iter(test_person_dataloader)\n",
        "\n",
        "    iter_tops_mask = iter(test_tops_mask_dataloader)\n",
        "    iter_pants_mask=iter(test_pants_mask_dataloader)\n",
        "    iter_skirt_mask= iter(test_skirt_mask_dataloader)\n",
        "    \n",
        "    t1=time.time()\n",
        "    count=0\n",
        "    for tops_data in test_tops_mask_dataloader:\n",
        "          #0.バッチデータの取得     \n",
        "          person_real_batch=next(iter_person)\n",
        "          tops_mask_real_batch=next(iter_tops_mask)\n",
        "          pants_mask_real_batch=next(iter_pants_mask)\n",
        "          skirt_mask_real_batch=next(iter_skirt_mask)\n",
        "\n",
        "          person=person_real_batch[0].to(device)\n",
        "          tops_mask=tops_mask_real_batch[0].to(device)              #[][][][]\n",
        "          pants_mask=pants_mask_real_batch[0].to(device)      #[][][][]\n",
        "          skirt_mask=skirt_mask_real_batch[0].to(device)  \n",
        "          \n",
        "          b_size = tops.size(0)#バッチサイズを計算\n",
        "          #print(b_size)\n",
        "          \n",
        "          \n",
        "          #データの連結\n",
        "          seg=torch.cat([tops_mask,pants_mask,skirt_mask],dim=1)\n",
        "          \n",
        "         \n",
        "          #fakeを生成\n",
        "          if count==t:\n",
        "            fake=netG(_,seg,z,pre=True) #衣服のみ\n",
        "          #fake_image=overlay(person,fake,tops_mask,pants_mask,skirt_mask) #人物重ね合わせ\n",
        "            images.append(fake.detach())\n",
        "          count+=1\n",
        "      "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJ5SgNys2JxT"
      },
      "source": [
        "total=0\n",
        "fig=plt.figure(figsize=(90,90))\n",
        "for i in range(n*2*2):\n",
        "  for j in range(n*2*2):\n",
        "    plt.subplot(n*2*2,n*2*2,total+1)\n",
        "    plt.imshow(np.transpose(vutils.make_grid(images[total], padding=2, normalize=True).cpu(),(1,2,0)))\n",
        "    total+=1\n",
        "plt.savefig(\"image.png\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCDnNYDR5E2z"
      },
      "source": [
        "#損失を表示"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DbF5Chwy4-_n"
      },
      "source": [
        "fig=plt.figure(figsize=(10,5))\n",
        "plt.title(\"Generator and Discriminator Loss During Training\",fontsize=23)\n",
        "plt.plot(Generator_losses,label=\"G\")\n",
        "plt.plot( Discriminator_losses,label=\"D\")\n",
        "plt.xlabel(\"iterations\",fontsize=23)\n",
        "plt.ylabel(\"Loss\",fontsize=23)\n",
        "plt.tick_params(labelsize=17)\n",
        "#plt.ylim(0,10)\n",
        "#plt.xticks(np.arange(0,27001,10000))\n",
        "#plt.yticks(np.arange(0,11,5))\n",
        "plt.legend()\n",
        "plt.savefig(\"graphg.png\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IEa-2lgd5CQZ"
      },
      "source": [
        "fig=plt.figure(figsize=(10,5))\n",
        "plt.title(\"Sum Loss During Training\")\n",
        "plt.plot(Sum_losses,label=\"Unet\")\n",
        "#plt.plot( Discriminator_losses,label=\"D\")\n",
        "plt.xlabel(\"iterations\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.savefig(\"graph02\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sbGKA4uwqk18"
      },
      "source": [
        "fig=plt.figure(figsize=(10,5))\n",
        "plt.title(\"kld Loss During Training\")\n",
        "plt.plot(kld_losses,label=\"Unet\")\n",
        "#plt.plot( Discriminator_losses,label=\"D\")\n",
        "plt.xlabel(\"iterations\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "print(kld_losses[-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uX7hJ6ysqlP9"
      },
      "source": [
        "fig=plt.figure(figsize=(10,5))\n",
        "plt.title(\"L1 Loss During Training\")\n",
        "plt.plot(L1_losses,label=\"Unet\")\n",
        "#plt.plot( Discriminator_losses,label=\"D\")\n",
        "plt.xlabel(\"iterations\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.savefig(\"graph02.png\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2r0wrYIKiPR"
      },
      "source": [
        "fig=plt.figure(figsize=(10,5))\n",
        "plt.title(\"L1 Loss During Training\")\n",
        "plt.plot(tmapL1Losses,label=\"Unet\")\n",
        "#plt.plot( Discriminator_losses,label=\"D\")\n",
        "plt.xlabel(\"iterations\")\n",
        "plt.ylabel(\"Loss\")\n",
        "#plt.savefig(\"graph02\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xUWNlHBCK-Hz"
      },
      "source": [
        "#@title\n",
        "fig=plt.figure(figsize=(10,5))\n",
        "plt.title(\"L1 Loss During Training\")\n",
        "plt.plot(pmapL1Losses,label=\"Unet\")\n",
        "#plt.plot( Discriminator_losses,label=\"D\")\n",
        "plt.xlabel(\"iterations\")\n",
        "plt.ylabel(\"Loss\")\n",
        "#plt.savefig(\"graph02\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ainkpkBVK-8X"
      },
      "source": [
        "fig=plt.figure(figsize=(10,5))\n",
        "plt.title(\"L1 Loss During Training\")\n",
        "plt.plot(smapL1Losses,label=\"Unet\")\n",
        "#plt.plot( Discriminator_losses,label=\"D\")\n",
        "plt.xlabel(\"iterations\")\n",
        "plt.ylabel(\"Loss\")\n",
        "#plt.savefig(\"graph02\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bz1mgALnqlic"
      },
      "source": [
        "fig=plt.figure(figsize=(10,5))\n",
        "plt.title(\"vgg Loss During Training\")\n",
        "plt.plot(vgg_losses,label=\"Unet\")\n",
        "#plt.plot( Discriminator_losses,label=\"D\")\n",
        "plt.xlabel(\"iterations\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.savefig(\"graph03\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXP9S4gqEZBo"
      },
      "source": [
        "fig=plt.figure(figsize=(10,5))\n",
        "plt.title(\"Unet Loss During Training\")\n",
        "plt.plot(judge1,label=\"Dt\")\n",
        "plt.plot(judge2,label=\"Df\")\n",
        "plt.plot(judge3,label=\"Gf\")\n",
        "plt.xlabel(\"iterations\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1C8x9ORbnRML"
      },
      "source": [
        "#退避"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aj03-0uTn2VN"
      },
      "source": [
        "%cd .."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7nJ8hcALn4jy"
      },
      "source": [
        "%cd drive/My\\ Drive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wgWQN8jqKyhP"
      },
      "source": [
        "def avoid_G():    \n",
        "    PATHUnet='drive/My Drive/DiversityDesign_data/model/Encoder_Decoder2.pth'\n",
        "    torch.save({\n",
        "            'epoch': epoch,\n",
        "            #'image':img_list,\n",
        "            'Sum_losses':Sum_losses,\n",
        "            'Generator':Generator_losses,\n",
        "            'Vgg':vgg_losses,\n",
        "            'kld':kld_losses,\n",
        "            'L1':L1_losses,\n",
        "            'judge1':judge1,\n",
        "            'judge2':judge2,\n",
        "            'judge3':judge3,\n",
        "            'model_state_dict': netG.state_dict(),\n",
        "            'optimizer_state_dict': optimizernetG.state_dict(),\n",
        "            'criterion1':Ladv.state_dict(),\n",
        "            'criterion2':L1.state_dict(),\n",
        "            'criterion3':Lper.state_dict()\n",
        "\n",
        "            }, PATHUnet)\n",
        "def avoid_D():\n",
        "    PATHD='drive/My Drive/DiversityDesign_data/models/Discriminator2.pth'\n",
        "    torch.save({\n",
        "            'Disciriminator_losses':Discriminator_losses,\n",
        "            'model_state_dict': netD.state_dict(),\n",
        "            'optimizer_state_dict': optimizernetD.state_dict()\n",
        "            }, PATHD)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xt9clXWZoJkY"
      },
      "source": [
        "avoid_G()\n",
        "avoid_D()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "teIykXZQoV_x"
      },
      "source": [
        "#ロード"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xoBOTMncoahK"
      },
      "source": [
        "PATHG='drive/My Drive/DiversityDesign_data/model/Encoder_Decoder.pth'\n",
        "#Unet = EncoderDecoder(ngpu).to(device)\n",
        "optimizernetG= optim.Adam(netG.parameters(),lr=lr,betas=(b1,b2))\n",
        "Ladv=nn.BCELoss()\n",
        "L1=nn.L1Loss()\n",
        "Lper=Vgg19Loss().to(device)\n",
        "\n",
        "checkpoint = torch.load(PATHG)\n",
        "netG.load_state_dict(checkpoint['model_state_dict'])\n",
        "optimizernetG.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "Ladv.load_state_dict(checkpoint['criterion1'])\n",
        "L1.load_state_dict(checkpoint['criterion2'])\n",
        "Lper.load_state_dict(checkpoint['criterion3'])\n",
        "epoch = checkpoint['epoch']\n",
        "#img_list=checkpoint['image']\n",
        "Sum_losses=checkpoint['Sum_losses']\n",
        "Generator_losses=checkpoint['Generator']\n",
        "kld_losses=checkpoint['kld']\n",
        "vgg_losses=checkpoint['Vgg']\n",
        "L1_losses=checkpoint[\"L1\"]\n",
        "judge1=checkpoint['judge1']\n",
        "judge2=checkpoint['judge2']\n",
        "judge3=checkpoint['judge3']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7-YxPjPo6WR"
      },
      "source": [
        "PATHD='drive/My Drive/DiversityDesign_data/model/Discriminator.pth'\n",
        "\n",
        "optimizernetD=optim.Adam(netD.parameters(),lr=lr,betas=(b1,b2))\n",
        "\n",
        "\n",
        "checkpoint = torch.load(PATHD)\n",
        "netD.load_state_dict(checkpoint['model_state_dict'])\n",
        "optimizernetD.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "Discriminator_losses=checkpoint['Disciriminator_losses']"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}